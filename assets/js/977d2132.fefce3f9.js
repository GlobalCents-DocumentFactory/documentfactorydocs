"use strict";(self.webpackChunkdocumentfactorydocs=self.webpackChunkdocumentfactorydocs||[]).push([[7642],{9921:(e,o,n)=>{n.r(o),n.d(o,{assets:()=>a,contentTitle:()=>i,default:()=>p,frontMatter:()=>r,metadata:()=>c,toc:()=>d});var t=n(4848),s=n(8453);const r={sidebar_position:3,title:"Terminology & Concepts"},i="Terminology & Concepts",c={id:"getting-started/terminology_and_concepts",title:"Terminology & Concepts",description:"This section provides definitions and explanations of fundamental terms and concepts used throughout the documentation.",source:"@site/docs/getting-started/terminology_and_concepts.mdx",sourceDirName:"getting-started",slug:"/getting-started/terminology_and_concepts",permalink:"/documentfactorydocs/docs/getting-started/terminology_and_concepts",draft:!1,unlisted:!1,editUrl:"https://github.com/GlobalCents-DocumentFactory/documentfactorydocs/tree/main/docs/getting-started/terminology_and_concepts.mdx",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3,title:"Terminology & Concepts"},sidebar:"tutorialSidebar",previous:{title:"Typical Workflow",permalink:"/documentfactorydocs/docs/getting-started/typical_workflow"},next:{title:"Configuration",permalink:"/documentfactorydocs/docs/category/configuration"}},a={},d=[{value:"Pipeline",id:"pipeline",level:2},{value:"Workflow",id:"workflow",level:2},{value:"Task",id:"task",level:2},{value:"Job Processor",id:"job-processor",level:2},{value:"Document Processor",id:"document-processor",level:2}];function l(e){const o={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",mermaid:"mermaid",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(o.header,{children:(0,t.jsx)(o.h1,{id:"terminology--concepts",children:"Terminology & Concepts"})}),"\n",(0,t.jsx)(o.p,{children:"This section provides definitions and explanations of fundamental terms and concepts used throughout the documentation.\nIt serves as a reference point for understanding how DocumentFactory works at a conceptual level."}),"\n",(0,t.jsx)(o.h2,{id:"pipeline",children:"Pipeline"}),"\n",(0,t.jsxs)(o.p,{children:["A pipeline is the core configuration element that defines how documents are processed in ",(0,t.jsx)(o.strong,{children:"DocumentFactory"}),". I\nIt specifies the sequence of operations applied to incoming files, enabling a flexible and automated transformation workflow."]}),"\n",(0,t.jsx)(o.p,{children:"The pipeline configuration includes the following logical components:"}),"\n",(0,t.jsxs)(o.ul,{children:["\n",(0,t.jsxs)(o.li,{children:["\n",(0,t.jsxs)(o.p,{children:[(0,t.jsx)(o.strong,{children:"Processors"})," \u2013 define the primary operations on individual files, such as format conversion or Optical Character Recognition (OCR)."]}),"\n"]}),"\n",(0,t.jsxs)(o.li,{children:["\n",(0,t.jsxs)(o.p,{children:[(0,t.jsx)(o.strong,{children:"Merge"})," \u2013 controls whether multiple documents should be combined into a single output file."]}),"\n"]}),"\n",(0,t.jsxs)(o.li,{children:["\n",(0,t.jsxs)(o.p,{children:[(0,t.jsx)(o.strong,{children:"Postprocessors"})," \u2013 specify operations that are applied after the main processing steps, such as adding watermarks or compressing output files."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(o.mermaid,{value:"graph LR;\n    doc_1(pdf)--\x3ep_1_1(processor 1)--\x3ep_2_1(processor 2)--\x3em(Merge)--\x3er_1(pdf,word,html...)--\x3epp(postprocessor 1)--\x3er_2(pdf,word,html...)\n    doc_2(word)--\x3ep_1_2(processor 1)--\x3ep_2_2(processor 2)--\x3em\n    doc_3(powerpoint)--\x3ep_1_3(processor 1)--\x3ep_2_3(processor 2)--\x3em"}),"\n",(0,t.jsx)(o.p,{children:"DocumentFactory uses the pipeline to determine exactly what should happen to each document and in what order. Whether converting documents, enhancing them for search, or preparing them for long-term archiving, the pipeline provides a structured and reusable way to define processing rules."}),"\n",(0,t.jsx)(o.p,{children:"The pipeline is provided as a JSON-formatted input parameter when starting a processing task. It can be created and modified manually or through available user interfaces."}),"\n",(0,t.jsx)(o.p,{children:"In essence, the pipeline is the central control point that guides document transformation\u2014enabling automation, consistency, and efficiency across all processed content."}),"\n",(0,t.jsx)(o.h2,{id:"workflow",children:"Workflow"}),"\n",(0,t.jsx)(o.p,{children:"A workflow is the runtime process in which a defined pipeline is applied to actual input data. It represents the execution phase,\nwhere documents or folder structures are processed step by step according to the pipeline\u2019s logic. Each workflow instance is tied\nto a specific set of input and operates independently to produce results."}),"\n",(0,t.jsx)(o.h2,{id:"task",children:"Task"}),"\n",(0,t.jsxs)(o.p,{children:["A ",(0,t.jsx)(o.strong,{children:"Task"})," is the fundamental unit of execution within a workflow. Each task represents the execution of a single step:\neither an operation from the ",(0,t.jsx)(o.code,{children:"Processors"})," list, an operation from the ",(0,t.jsx)(o.code,{children:"Postprocessors"})," list, or a Merge action performed\non a specific document or group of documents."]}),"\n",(0,t.jsx)(o.p,{children:"This approach breaks down the document processing lifecycle into manageable, discrete actions,\neach encapsulated as a separate task."}),"\n",(0,t.jsx)(o.h2,{id:"job-processor",children:"Job Processor"}),"\n",(0,t.jsxs)(o.p,{children:["A ",(0,t.jsx)(o.strong,{children:"Job Processor"})," is a specialized component in the execution pipeline, instantiated based on the file extension of the\ndocument being processed. For each incoming file\u2014whether it be a PDF, Word document, image, or another supported format \u2014\nthe system selects the appropriate Job Processor (e.g., PDFProcessor, WordProcessor, ImageProcessor) tailored to handle that file type."]}),"\n",(0,t.jsx)(o.p,{children:"The primary responsibility of the Job Processor is to interpret the task configuration and determine the set of actions\nthat need to be applied to the document. Based on this configuration, the Job Processor creates one or more\nDocument Processors, each responsible for carrying out a specific action as defined by the pipeline (such as merging documents,\nconverting formats, or applying watermarks)."}),"\n",(0,t.jsx)(o.h2,{id:"document-processor",children:"Document Processor"}),"\n",(0,t.jsxs)(o.p,{children:["A ",(0,t.jsx)(o.strong,{children:"Document Processor"})," operates at a finer level of granularity than the Job Processor. While the Job Processor manages\nthe overall logic for a document or group of documents, the Document Processor executes individual actions assigned to it\nby the Job Processor. Each Document Processor is configured according to the specifics of a task\u2014performing actions\nsuch as merging, converting, or watermarking on the actual content of a document."]}),"\n",(0,t.jsx)(o.p,{children:"The relationship between Job Processors and Document Processors is determined by the structure of operations within the pipeline:"}),"\n",(0,t.jsxs)(o.ul,{children:["\n",(0,t.jsx)(o.li,{children:"If a processor operation (in either the Processors or Postprocessors list) consists of a single action, the Job Processor\nwill create exactly one corresponding Document Processor for that task."}),"\n",(0,t.jsx)(o.li,{children:"If an operation defines multiple actions\u2014such as a composite operation that involves several steps\u2014the Job Processor splits\nthese actions, creating a separate Document Processor for each one."}),"\n"]})]})}function p(e={}){const{wrapper:o}={...(0,s.R)(),...e.components};return o?(0,t.jsx)(o,{...e,children:(0,t.jsx)(l,{...e})}):l(e)}},8453:(e,o,n)=>{n.d(o,{R:()=>i,x:()=>c});var t=n(6540);const s={},r=t.createContext(s);function i(e){const o=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(o):{...o,...e}}),[o,e])}function c(e){let o;return o=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),t.createElement(r.Provider,{value:o},e.children)}}}]);